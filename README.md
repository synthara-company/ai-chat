# ğŸ‰ Dragon AI

<div align="center">

[![Play Demo](https://img.shields.io/badge/â–¶ï¸_Play_Demo-000?style=for-the-badge)](https://dragon-ai-pi.vercel.app)
[![Documentation](https://img.shields.io/badge/ğŸ“š_Docs-000?style=for-the-badge)](https://dragon-ai.vercel.app/docs)
[![GitHub](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»_GitHub-000?style=for-the-badge)](https://github.com/bniladridas/dragon-ai)
[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fvercel%2Fexamples%2Ftree%2Fmain%2Fpython%2Fflask3&demo-title=Flask%203%20%2B%20Vercel&demo-description=Use%20Flask%203%20on%20Vercel%20with%20Serverless%20Functions%20using%20the%20Python%20Runtime.&demo-url=https%3A%2F%2Fflask3-python-template.vercel.app%2F&demo-image=https://assets.vercel.com/image/upload/v1669994156/random/flask.png)

![Version](https://img.shields.io/badge/version-2.0.0-blue.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.8%2B-blue)
![Flask](https://img.shields.io/badge/flask-3.0%2B-green)
![Gemini](https://img.shields.io/badge/gemini-1.5--flash-orange)
![Vercel](https://img.shields.io/badge/vercel-latest-black)
[![Uptime](https://img.shields.io/badge/uptime-99.9%25-brightgreen.svg)](https://status.dragon-ai.vercel.app)

<p align="center">
  <b>A powerful AI chat interface powered by Google's Gemini 1.5 Flash model</b><br>
  <sub>Built with Flask 3, Vercel, and modern web technologies ğŸš€</sub>
</p>

[Demo](https://dragon-ai-pi.vercel.app) â€¢ 
[Documentation](https://dragon-ai.vercel.app/docs) â€¢ 
[Quick Start](#quick-start) â€¢ 
[Deployment](#deployment) â€¢ 
[Contributing](#contributing)

</div>

## ğŸ® Quick Start

Try Dragon AI instantly:
1. ğŸŒ Visit [https://dragon-ai-pi.vercel.app](https://dragon-ai-pi.vercel.app)
2. ğŸ”’ No signup required
3. ğŸ’¬ Start chatting with the AI

Or run locally:
```bash
# Clone repository
git clone https://github.com/bniladridas/dragon-ai.git
cd dragon-ai

# Install Vercel CLI
npm i -g vercel

# Install dependencies
pip install -r requirements.txt

# Run development server
vercel dev
```

Your Flask application will be available at `http://localhost:3000`.

## âœ¨ What's New in 2.0.0

### Major Updates
- ğŸ¨ New Twitter/X-inspired dark theme UI
- ğŸš€ Vercel Edge Functions integration
- ğŸ¤– Upgraded to Gemini 1.5 Flash
- ğŸ“± Enhanced mobile responsiveness
- ğŸ”„ Real-time chat synchronization
- ğŸ¨ Custom SVG animations
- ğŸŒ Global CDN distribution
- âš¡ Flask 3.0 support

### Performance Improvements
- âš¡ 50% faster response times
- ğŸ“¦ Reduced bundle size
- ğŸ”§ Optimized API calls
- ğŸŒ Enhanced global latency

## â˜ï¸ Dragon AI Cloud Infrastructure

```mermaid
flowchart TB
    subgraph Client
        B[Browser] --> V[Vercel Edge Network]
    end
    
    subgraph Cloud["Cloud Infrastructure"]
        V --> VF[Vercel Frontend]
        V --> PS[Python Serverless Function]
        PS --> G[Google Gemini API]
        
        subgraph Vercel["Vercel Platform"]
            VF --> |Static Assets| VC[Vercel CDN]
            PS --> |Environment Variables| VE[Vercel ENV]
        end
    end
    
    subgraph Storage
        B --> |Chat History| LS[Local Storage]
    end
    
    style B fill:#1D9BF0,color:#fff
    style V fill:#000000,color:#fff
    style VF fill:#0070F3,color:#fff
    style PS fill:#16181C,color:#fff
    style G fill:#4285F4,color:#fff
    style VC fill:#0070F3,color:#fff
    style VE fill:#0070F3,color:#fff
    style LS fill:#1DA1F2,color:#fff
```

## ğŸ— How it Works

Dragon AI uses the Web Server Gateway Interface (WSGI) with Flask 3 to enable handling requests on Vercel with Serverless Functions. The architecture is designed as follows:

```mermaid
flowchart TB
    U[User Interface] --> |HTTP Request| F[Flask 3 Server]
    F --> |Prompt| G[Gemini 1.5 Flash API]
    G --> |Generated Response| F
    F --> |JSON Response| U
    
    subgraph Frontend
    U --> |Store| LC[Local Storage]
    LC --> |Load| U
    end
    
    subgraph Cloud Infrastructure
    F --> |Vercel Edge| V[Vercel Platform]
    V --> |CDN| C[Global CDN]
    end
```

## ğŸš€ Features

### Core Features
- ğŸ’¬ Real-time AI chat interface
- ğŸ“ Markdown & code syntax highlighting
- ğŸ’¾ Local chat history
- ğŸ“± Responsive design
- ğŸŒ™ Dark mode
- âš¡ Fast response times
- ğŸ”’ Secure API handling

### Technical Features
- ğŸ”„ WebSocket support
- ğŸ“¦ Efficient bundling
- ğŸŒ Edge network distribution
- ğŸ”§ Environment management
- ğŸ“Š Performance monitoring
- ğŸ” SEO optimization
- ğŸš€ CI/CD pipeline

## ğŸš€ Deployment

### Vercel Configuration
```json
{
  "version": 2,
  "builds": [
    {
      "src": "app.py",
      "use": "@vercel/python"
    }
  ],
  "routes": [
    {
      "src": "/(.*)",
      "dest": "app.py"
    }
  ]
}
```

### One-Click Deploy
Deploy the example using [Vercel](https://vercel.com?utm_source=github&utm_medium=readme&utm_campaign=vercel-examples):

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fvercel%2Fexamples%2Ftree%2Fmain%2Fpython%2Fflask3&demo-title=Flask%203%20%2B%20Vercel&demo-description=Use%20Flask%203%20on%20Vercel%20with%20Serverless%20Functions%20using%20the%20Python%20Runtime.&demo-url=https%3A%2F%2Fflask3-python-template.vercel.app%2F&demo-image=https://assets.vercel.com/image/upload/v1669994156/random/flask.png)

### Performance Metrics
- TTFB: ~100ms
- FCP: ~300ms
- LCP: ~800ms
- TTI: ~1.2s

## ğŸ’» Development

### Prerequisites
- Python 3.8+
- Node.js 14+
- Google Cloud API key
- Vercel account

### Environment Variables
```env
GOOGLE_API_KEY=your_api_key_here
VERCEL_ENV=development
DEBUG=True
```

## ğŸ“š API Documentation

### Generate Response
```http
POST /generate
Content-Type: application/json

{
  "prompt": "string",
  "chatId": "number"
}
```

### Response Format
```json
{
  "response": "string",
  "metadata": {
    "model": "gemini-1.5-flash",
    "timestamp": "string",
    "processTime": "number"
  }
}
```

## ğŸ”’ Security & Monitoring

### Security Features
- ğŸ” API key encryption
- ğŸ›¡ï¸ Rate limiting
- ğŸ” Input validation
- ğŸš« XSS protection
- ğŸ“ Security logs

### Monitoring Features
- ğŸ“ˆ Real-time metrics
- ğŸ” Error tracking
- ğŸ“Š Usage analytics
- âš¡ Performance monitoring
- ğŸŒ¡ï¸ Health checks

## ğŸ¤ Contributing

1. Fork repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Create Pull Request

## ğŸ“œ Code of Conduct

[View our Code of Conduct](CODE_OF_CONDUCT.md)

## ğŸ“„ License

MIT License - [View License](LICENSE)

## ğŸ™ Acknowledgments

- Google AI Team
- Vercel Platform
- Open Source Community

## ğŸ“ Support & Status

### Support Channels
- ğŸ“§ Email: support@dragon-ai.com
- ğŸ’¬ Discord: [Join](https://discord.gg/dragon-ai)
- ğŸ¦ Twitter: [@DragonAI](https://twitter.com/DragonAI)

### Status & Updates
- Status Page: [status.dragon-ai.vercel.app](https://status.dragon-ai.vercel.app)
- Blog: [blog.dragon-ai.vercel.app](https://blog.dragon-ai.vercel.app)
- Updates: [@DragonAIStatus](https://twitter.com/DragonAIStatus)

---

<div align="center">
  Made with â¤ï¸ by Dragon Team | Powered by Vercel<br>
  <sub>Â© 2024 Dragon AI. All rights reserved.</sub>
</div>